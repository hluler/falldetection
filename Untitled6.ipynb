{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from numpy import genfromtxt\n",
    "import numpy\n",
    "import codecs\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve,auc,accuracy_score\n",
    "from sklearn.metrics import precision_score,recall_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7671\n",
      "59\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 100)         63600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           101       \n",
      "=================================================================\n",
      "Total params: 63,701\n",
      "Trainable params: 63,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create a sequence classification instance\n",
    "def get_sequence(n_timesteps,time):\n",
    "    x = [data[index] for index in range((time*10)+1 ,(time*10)+10+1)]\n",
    "    x = numpy.delete(x, (data.shape[1]-1), axis=1)\n",
    "    x= numpy.array(x)\n",
    "    y = [Y[index] for index in range((time*10) ,(time*10)+10)]\n",
    "    y=numpy.array(y)\n",
    "    # reshape input and output data to be suitable for LSTMs\n",
    "    X = x.reshape(1, n_timesteps, (data.shape[1]-1))\n",
    "    y = y.reshape(1, n_timesteps, y.shape[1])\n",
    "    #y = np_utils.to_categorical(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "data = genfromtxt('/home/helong/Downloads/Fall-detection-master/Experiment2.csv', delimiter=',')\n",
    "m =[data[i][-1] for i in range(1,data.shape[0])]\n",
    "Y = np_utils.to_categorical(m)\n",
    "\n",
    "print(data.shape[0])\n",
    "print(data.shape[1])\n",
    "\n",
    "# define problem properties\n",
    "n_timesteps = 10\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(100,input_shape = (None, (data.shape[1]-1)),return_sequences=True))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(1, activation='softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.SGD(lr=0.0001)\n",
    "model.compile(loss='mean_squared_error', optimizer = \"adam\" , metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len is  5369\n",
      "valid_len is  6136\n",
      "test_len is  7670\n",
      "[0. 2. 2. ... 1. 1. 1.]\n",
      "y shape===== (1, 5368, 1)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7067 - acc: 0.1395\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5791 - acc: 0.6854\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4802 - acc: 0.6854\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4115 - acc: 0.6854\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3687 - acc: 0.6854\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3443 - acc: 0.6854\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3313 - acc: 0.6854\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3244 - acc: 0.6854\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3207 - acc: 0.6854\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3187 - acc: 0.6854\n",
      "fewfewf========ddd=====\n",
      "66.73176884651184\n",
      "fewfewf=============\n",
      "X shape===== (1, 10, 58)\n",
      "y shape===== (1, 10, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (None, 1) but got array with shape (10, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f418e72f0a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X shape====='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y shape====='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bird/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bird/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bird/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (None, 1) but got array with shape (10, 3)"
     ]
    }
   ],
   "source": [
    "#train_len = 7600  #int(len(data)*0.7)\n",
    "#valid_len = 7700 #int(len(data)*0.8)\n",
    "#test_len = 7000  #len(data)-1\n",
    "train_len = int(len(data)*0.7)\n",
    "valid_len = int(len(data)*0.8)\n",
    "test_len = len(data)-1\n",
    "\n",
    "print(\"train_len is \",train_len)\n",
    "print(\"valid_len is \",valid_len)\n",
    "print(\"test_len is \",test_len)\n",
    "\n",
    "x1 = [data[index] for index in range(4600, valid_len)]\n",
    "\n",
    "\n",
    "#print(x1.head())\n",
    "\n",
    "x1 = numpy.delete(x1, (data.shape[1]-1), axis=1)\n",
    "x1 = numpy.array(x1)\n",
    "y1 = [data[index][-1] for index in range(4600, valid_len)]\n",
    "y1 = numpy.array(y1)\n",
    "# reshape input and output data to be suitable for LSTMs\n",
    "X1 = x1.reshape(1, valid_len-4600, data.shape[1]-1)\n",
    "y1 = y1.reshape(1, valid_len-4600, 1)\n",
    "\n",
    "x = [data[index] for index in range(1, train_len)]\n",
    "x = numpy.delete(x, (data.shape[1]-1), axis=1)\n",
    "x = numpy.array(x)\n",
    "y = [data[index][-1] for index in range(1, train_len)]\n",
    "\n",
    "y = numpy.array(y)\n",
    "print(y)\n",
    "# reshape input and output data to be suitable for LSTMs\n",
    "X = x.reshape(1, train_len-1, data.shape[1]-1)\n",
    "y = y.reshape(1, train_len-1, 1)\n",
    "\n",
    "print('y shape=====', y.shape)\n",
    "\n",
    "x2 = [data[index] for index in range(6000, test_len)]\n",
    "x2 = numpy.delete(x2, (data.shape[1]-1), axis=1)\n",
    "x2 = numpy.array(x2)\n",
    "y2 = [data[index][-1] for index in range(6000, test_len)]\n",
    "y2 = numpy.array(y2)\n",
    "# reshape input and output data to be suitable for LSTMs\n",
    "X2 = x2.reshape(1, test_len-6000, data.shape[1]-1)\n",
    "y2 = y2.reshape(1, test_len-6000, 1)\n",
    "\n",
    "model.fit(X, y,batch_size=10, epochs = 10,verbose=1)\n",
    "\n",
    "print('fewfewf========ddd=====')\n",
    "\n",
    "scores = model.evaluate(X1,y1,verbose=0)\n",
    "print(scores[1]*100)\n",
    "\n",
    "print('fewfewf=============')\n",
    "\n",
    "\n",
    "#yhat = model.predict(X1,verbose=0)[0]\n",
    "\n",
    "\n",
    "# train LSTM\n",
    "for epoch in range(0,20):\n",
    "    # generate new random sequence\n",
    "    X,y = get_sequence(n_timesteps,epoch)\n",
    "    # fit model for one epoch on this sequence\n",
    "    print('X shape=====', X.shape)\n",
    "    print('y shape=====', y.shape)\n",
    "    model.fit(X, y,batch_size=1, verbose=0)\n",
    "    \n",
    "print('=================')\n",
    "    \n",
    "for epoch in range(30,50):\n",
    "\t# generate new random sequence\n",
    "\tX,y = get_sequence(n_timesteps,epoch)\n",
    "\t# fit model for one epoch on this sequence\n",
    "\tmodel.fit(X, y,batch_size=1, verbose=0)\n",
    "    \n",
    "for epoch in range(60,80):\n",
    "\t# generate new random sequence\n",
    "\tX,y = get_sequence(n_timesteps,epoch)\n",
    "\t# fit model for one epoch on this sequence\n",
    "\tmodel.fit(X, y,batch_size=1, verbose=0)    \n",
    "    \n",
    "for epoch in range(90,110):\n",
    "\t# generate new random sequence\n",
    "\tX,y = get_sequence(n_timesteps,epoch)\n",
    "\t# fit model for one epoch on this sequence\n",
    "\tmodel.fit(X, y,batch_size=1, verbose=0)\n",
    "\n",
    "for epoch in range(120,140):\n",
    "\t# generate new random sequence\n",
    "\tX,y = get_sequence(n_timesteps,epoch)\n",
    "\t# fit model for one epoch on this sequence\n",
    "\tmodel.fit(X, y,batch_size=1, verbose=0)\n",
    "\n",
    "countp=0\n",
    "countn=0\n",
    "\n",
    "ypredicted =  []\n",
    "yactual = []\n",
    "\n",
    "\n",
    "\n",
    "for d in range(20,30):\n",
    "        X,y = get_sequence(n_timesteps,d)\n",
    "        #yactual[] = [y[i] for i in range(len(y))]\n",
    "        yhat = model.predict(X,verbose=0)[0]\n",
    "        for index1 in range(10):\n",
    "            i = np.where(yhat[index1] == yhat[index1].max())\n",
    "            hin = i[0]\n",
    "            for index2 in range(2):\n",
    "                if(index2==hin):\n",
    "                    yhat[index1][index2]=1\n",
    "                else:\n",
    "                    yhat[index1][index2]=0IMG_SIZE_2\n",
    "        j= yhat\n",
    "        k= y[0]\n",
    "        for index1 in range(10):\n",
    "            ypredicted.append(j[index1])\n",
    "            yactual.append(k[index1])\n",
    "         \n",
    "            \n",
    "for d in range(50,60):\n",
    "        X,y = get_sequence(n_timesteps,d)\n",
    "        #yactual[] = [y[i] for i in range(len(y))]\n",
    "        yhat = model.predict(X,verbose=0)[0]\n",
    "        for index1 in range(10):\n",
    "            i = np.where(yhat[index1] == yhat[index1].max())\n",
    "            hin = i[0]\n",
    "            for index2 in range(2):\n",
    "                if(index2==hin):\n",
    "                    yhat[index1][index2]=1\n",
    "                else:\n",
    "                    yhat[index1][index2]=0\n",
    "        j= yhat\n",
    "        k= y[0]\n",
    "        for index1 in range(10):\n",
    "            ypredicted.append(j[index1])\n",
    "            yactual.append(k[index1])\n",
    "            \n",
    "for d in range(80,90):\n",
    "        X,y = get_sequence(n_timesteps,d)\n",
    "        #yactual[] = [y[i] for i in range(len(y))]\n",
    "        yhat = model.predict(X,verbose=0)[0]\n",
    "        for index1 in range(10):\n",
    "            i = np.where(yhat[index1] == yhat[index1].max())\n",
    "            hin = i[0]\n",
    "            for index2 in range(2):\n",
    "                if(index2==hin):\n",
    "                    yhat[index1][index2]=1\n",
    "                else:\n",
    "                    yhat[index1][index2]=0\n",
    "        j= yhat\n",
    "        k= y[0]\n",
    "        for index1 in range(10):\n",
    "            ypredicted.append(j[index1])\n",
    "            yactual.append(k[index1])\n",
    "        \n",
    "for d in range(110,120):\n",
    "        X,y = get_sequence(n_timesteps,d)\n",
    "        #yactual[] = [y[i] for i in range(len(y))]\n",
    "        yhat = model.predict(X,verbose=0)[0]\n",
    "        for index1 in range(10):\n",
    "            i = np.where(yhat[index1] == yhat[index1].max())\n",
    "            hin = i[0]\n",
    "            for index2 in range(2):\n",
    "                if(index2==hin):\n",
    "                    yhat[index1][index2]=1\n",
    "                else:\n",
    "                    yhat[index1][index2]=0\n",
    "        j= yhat\n",
    "        k= y[0]\n",
    "        for index1 in range(10):\n",
    "            ypredicted.append(j[index1])\n",
    "            yactual.append(k[index1])\n",
    "\n",
    "for d in range(140,150):\n",
    "        X,y = get_sequence(n_timesteps,d)\n",
    "        #yactual[] = [y[i] for i in range(len(y))]\n",
    "        yhat = model.predict(X,verbose=0)[0]\n",
    "        for index1 in range(10):\n",
    "            i = np.where(yhat[index1] == yhat[index1].max())\n",
    "            hin = i[0]\n",
    "            for index2 in range(2):\n",
    "                if(index2==hin):\n",
    "                    yhat[index1][index2]=1\n",
    "                else:\n",
    "                    yhat[index1][index2]=0\n",
    "        j= yhat\n",
    "        k= y[0]\n",
    "        for index1 in range(10):\n",
    "            ypredicted.append(j[index1])\n",
    "            yactual.append(k[index1])\n",
    "            \n",
    "\n",
    "            \n",
    "ya = []\n",
    "yp = []\n",
    "\n",
    "\n",
    "for index1 in range(len(ypredicted)):\n",
    "            if (ypredicted[index1][0]==1 and ypredicted[index1][1]==0 ):\n",
    "                yp.append(0)\n",
    "            if (ypredicted[index1][0]==0 and ypredicted[index1][1]==1 ):\n",
    "                yp.append(1)\n",
    "\n",
    "\n",
    "for index1 in range(len(yactual)):\n",
    "            if (yactual[index1][0]==1 and yactual[index1][1]==0 ):\n",
    "                ya.append(0)\n",
    "            if (yactual[index1][0]==0 and yactual[index1][1]==1 ):\n",
    "                ya.append(1)\n",
    "\n",
    "\n",
    "for i in range(len(ya)):\n",
    "    if(ya[i] == yp[i]):\n",
    "                countp = countp+1\n",
    "    else:\n",
    "        if(i!=len(ya)-1):\n",
    "            if((ya[i+1]!=0 and yp[i]!=0) or (ya[i-1]!=0 and yp[i]!=0)):\n",
    "                countp=countp+1\n",
    "            else:\n",
    "                countn = countn+1\n",
    "        else:\n",
    "            countn = countn+1\n",
    "\n",
    "\n",
    "yaa=[]\n",
    "ypp=[]\n",
    "for i in range(len(ya)):\n",
    "    if(ya[i]==yp[i]):\n",
    "        yaa.append(ya[i])\n",
    "        ypp.append(yp[i])\n",
    "    else:\n",
    "        if(ya[i]!=yp[i]):\n",
    "            if((ya[i]==1 and yp[i+1]==1) or (ya[i-1]==1 and yp[i]==1) or (ya[i]==1 and yp[i-1]==1) or (ya[i+1]==1 and yp[i]==1)):\n",
    "                yaa.append(1)\n",
    "                ypp.append(1)\n",
    "            else:\n",
    "                yaa.append(ya[i])\n",
    "                ypp.append(yp[i])\n",
    "\n",
    "conf_arr = confusion_matrix(yaa, ypp)\n",
    "conf_arr_1 = confusion_matrix(ya, yp)\n",
    "\n",
    "Precision = precision_score(yaa, ypp,average='micro') \n",
    "Recall = recall_score(yaa, ypp,average='micro')\n",
    "classification_report(yaa, ypp)\n",
    "print(classification_report(ya, yp))\n",
    "print(accuracy_score(ya,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
